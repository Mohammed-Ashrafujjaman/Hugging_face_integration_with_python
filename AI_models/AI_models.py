'''
Group Name: Sydney Group 17
Group Members: 4
Mohammed Ashrafujjaman Hera - 391197
Pujan Dey  - 395076
Shaown Imtiaz - 396121   # Generative AI part
Al-Amin Dhaly - 395230   # Image Classifier part
'''

from transformers import pipeline
from transformers import T5Tokenizer, T5ForConditionalGeneration 

class AIModels:
    def __init__(self):
        # Name of both of the AI Model used in this project classifier model
        # This one is for image classification
        self._imgClassifier_modelName = "google/vit-base-patch16-224"
        
        # This one is for generative AI by Google
        self._genAI_modelName = "google/flan-t5-base"
        
        # creating pipeline for both of the AI model
        self.ImgClassifier = self._image_classification_pipeline(self._imgClassifier_modelName)
        self.genAITokenizer, self.genAIModel = self._generative_AI_pipeline(self._genAI_modelName)
        
    # Implementation
    # Creating HuggingFace image classification pipeline ( google/vit-base-patch16-224 )
    def _image_classification_pipeline(self, modelName):
        return pipeline("image-classification", model=modelName)
        
    # Returning the name of the image classifier model 
    def get_ImageClassifierAI_model_name(self):
        return self._imgClassifier_modelName
    
    # Running the classification with an image path and get and output
    def run_image_classifier(self, imgPath):
        output = self.ImgClassifier(imgPath)
        return output
    
    # Creating HuggingFace generative AI model (google/flan-t5-base) 
    def _generative_AI_pipeline(self,modelName):
        tokenizer = T5Tokenizer.from_pretrained(modelName, legacy=False)
        model = T5ForConditionalGeneration.from_pretrained(modelName)
        return tokenizer,model
    
    # Returning the name of the Generative AI models
    def get_genAI_model_name(self):
        return self._genAI_modelName
    
    # running the Gen AI model and generate an output and returning it
    def run_generative_AI(self, inputText):
        # Tokenizing the input text
        input_ids = self.genAITokenizer(inputText, return_tensors="pt").input_ids
        # generating the output using users input
        outputs = self.genAIModel.generate(input_ids, max_new_tokens=50)
        # decoding and returing the output generated by AI model
        return self.genAITokenizer.decode(outputs[0], skip_special_tokens=True)
              
              
# This from below was used for tesing only this file  
# we wanted to make sure out code is really working only for the python file
# When we inherite this file into gui.py file code below this line won't execute
if __name__ == "__main__":
    AIs = AIModels()
    
    # Test with sample image
    img_path = "D:/software_now/Assignment_3/Hugging_face_integration_with_python/utils/cat.jpg"
    img_output = AIs.run_image_classifier(img_path)
    print(img_output[0]["label"])
    
    prompt1 = "Summarize: The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel..."
    output = AIs.run_mini_generative_AI(prompt1)
    print(output)
    
    prompt2 = "What is the capital of Japan?" 
    output = AIs.run_mini_generative_AI(prompt2)
    print(output)
    
    prompt3 = "Classify sentiment: I am really happy with this product!"
    output = AIs.run_mini_generative_AI(prompt3)
    print(output)
    
    

"""
REFERENCES
[1] Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes)
    at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224. 
    https://huggingface.co/google/vit-base-patch16-224
    
[2] google/flan-t5-base is a fine-tuned T5 transformer model optimized for general-purpose language tasks using 
    instruction tuning on a variety of datasets.
    https://huggingface.co/google/flan-t5-base

"""